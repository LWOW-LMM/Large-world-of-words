# Large world of words
_Katherine Elizabeth Abramski_, _Massimo Stella_, _Riccardo Improta_, _Giulio Rossetti_

<p align="center">
  <img src="LWOW Logo.jpg" alt="Logo" width="300"/>
</p>

Large World of Words is a dataset of free associations generated by various large language models (LLMs) including Mistral, LLaMA 3, Claude Haiku, GPT-3.5, GPT-4, and GPT-4o. This project is inspired by the Small World of Words (SWOW), which collected human-generated word associations. LWOW aims to create a vast network of word connections produced by AI models, potentially revealing insights into how these models process and link language concepts.


-------

### What are Free Associations?
Free associations are spontaneous mental connections between words or ideas. When presented with a stimulus word, a person (or in this case, an AI model) responds with the first word or concept that comes to mind. These associations reveal mental pathways that connect different concepts, often reflecting underlying patterns of thought, memory, or language structure. For example, given the word "tree," a common free association might be "leaf." These associations reveal mental pathways that connect different concepts, often reflecting underlying patterns of thought, memory, or language structure.

### How can they be used?
In psychology, free associations are a tool to study the unconscious mind, linguistic networks, and cognitive processes. They help researchers understand how people mentally organize and access information. In modern cognitive psychology, free association tasks are used to explore semantic memory, creativity, and the ways individuals connect ideas. By mapping these connections, psychologists gain insight into how the brain processes, retrieves, and categorizes information.

### LLMs and Gender Bias: a free association study

To explore gender biases, we used the LWOW dataset to examine how different AI models associate words with gender. We gave the AI models words like "woman" or "man" and looked at what other words they connected to these. We simulated spreading activation processes in the word association networks. The analysis revealed significant differences in activation levels for gender-related targets depending on the prime type, with higher activation for stereotype-consistent pairs. This kind of analysis helps us understand how AI systems might perpetuate gender stereotypes and guides efforts to create fairer, more equitable AI technologies.

------

## Technical notes
The dataset includes:
- 1228200 associations from LLama3
- 1228200 associations from Mistral
- 1228200 associations from Claude Haiku
- 3110 associations from ChatGPT 3.5 focalized on gender bias.
- 3110 associations from ChatGPT 4 focalized on gender bias.
- 3110  associations from ChatGPT 4o focalized on gender bias.
  
These associations were generated either via API or locally, depending on the LLM.

The dataset is modeled after the SWOW English word association norms, using the same 12,282 cue words. Each cue word is repeated 100 times, with 3 responses generated per cue.

For some models, participant profiles from the original SWOW experiment were also provided to allow investigation of how well the LLMs could simulate specific demographics.

The LLMs were prompted with the following task:
```
"Task:- You will be provided with an input word: write the first 3 words you associate to it separated by a comma.
- No additional output text is allowed.
               
Constraints:
- using the profile is mandatory for the task.
- no carriage return characters are allowed in the answers.
- answers should be as short as possible.
                           
Example:
Input: sea
Output: water,beach,sun"
```
The system prompt was:
```
"You are an agent that writes a single word at a time."
```

The responses was preprocessed and cleaned by considering various steps.

### Validation

The datasets were validated using data from the Semantic Priming Project, which implements a lexical decision task to study semantic priming effects. Spreading activation processes were simulated on the constructed networks, showing significant correlations with human reaction time data.

------

## Do you want to know more? Read the Preprint!

[QR TODO]

#### Citation
[TO BE ADDED AFTER PUBLICATION]

-----

## Further Information


### Funding & Legal
[TO DO]
Riccardo Improta is supported by the COGNOSCO grant funded by Università di Trento (Grant ID: PS 22_27).

### Contacts

For speaking requests and enquiries, please contact:

Katherine Elizabeth Abramski

katherine.abramski@phd.unipi.it 



### References



_Abramski, K., Citraro, S., Lombardi, L., Rossetti, G., & Stella, M. (2023). Cognitive network science reveals bias in gpt-3, gpt-3.5 turbo, and gpt-4 mirroring math anxiety in high-school students. Big Data and Cognitive Computing, 7(3), 124._

_Abramski, K., Lavorati, C., Rossetti, G., & Stella, M. (2024). LLM-Generated Word Association Norms. In HHAI 2024: Hybrid Human AI Systems for the Social Good (pp. 3-12). IOS Press._

_De Deyne, S., Navarro, D. J., Perfors, A., Brysbaert, M., & Storms, G. (2019). The “Small World of Words” English word association norms for over 12,000 cue words. Behavior research methods, 51, 987-1006._ [Small World of Words Project](https://smallworldofwords.org/en/project/)

